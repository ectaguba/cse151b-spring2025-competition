# @package _global_.model
type: st_vit             # ← maps to SpatiotemporalViT in get_model()

# --- ViT-style hyper-parameters (keep keys consistent with other models) ---
hidden_channels: 512    # this is our 'd_model' (embedding size of each patch token)
depth: 8                # number of TransformerEncoder layers
n_heads: 16            # number of attention heads
patch_size: 12           # side‐length P of each patch (H and W must be divisible by this)
dropout_rate: 0.1       # dropout applied inside Transformer embedding

# If you want to tune later, you could also add:
window_length: 12
# (but window_length is already defined in data.yaml as cfg.data.window_length)
# bug: for some reason you have to define model.window_length == data.window_length, its stupid


# # good:
# hidden_channels: 512    
# depth: 8                
# n_heads: 16             
# patch_size: 12           
# dropout_rate: 0.1       
# window_length: 9
# lr: 1e-4